# 开源词典和同义词项目调研

> 调研日期：2026-02-18
> 目的：为英语学习应用的"同义词识别"功能寻找可用的开源数据源

---

## 一、英汉基础词典

### 1. ECDICT（推荐）

- **项目地址**: https://github.com/skywind3000/ECDICT
- **数据格式**: CSV / SQLite / MySQL
- **数据量**: 基础版 76 万词条，完整版 340+ 万词条
- **字段**: 单词、音标、中英文释义、词频(BNC/COCA)、考试标签(CET4/6/IELTS/TOEFL/GRE)、词形变化
- **例句**: 无
- **许可证**: MIT
- **Python 集成**: 自带 Python 脚本，CSV 转 SQLite，原生查询接口
- **评价**: 最适合集成的英汉词典，数据量大、格式规范

### 2. CC-CEDICT（汉英方向）

- **项目地址**: https://cc-cedict.org/
- **下载**: https://www.mdbg.net/chinese/dictionary?page=cc-cedict
- **Python 解析库**: https://github.com/edvardsr/cc-cedict
- **JSON 转换工具**: https://github.com/kevb34ns/CEDICT2JSON
- **数据格式**: 自定义文本（`繁体 简体 [拼音] /英文释义1/英文释义2/`）
- **数据量**: ~124,331 词条
- **许可证**: CC BY-SA 4.0
- **评价**: 方向是"中→英"，适合汉英查询场景

### 3. 103976 英语单词库

- **项目地址**: https://github.com/1eez/103976
- **数据格式**: SQL / CSV / Excel
- **数据量**: 103,976 个英语单词
- **许可证**: MIT
- **评价**: 中等规模，适合基础应用

### 4. DictionaryData（400+ 本单词书）

- **项目地址**: https://github.com/LinXueyuanStdio/DictionaryData
- **数据格式**: CSV / JSON
- **数据量**: 400+ 本单词书，60,000+ 单词
- **覆盖范围**: 小学、中学、高中、考研、考博、GRE、托福等
- **许可证**: 未明确
- **评价**: 按考试/年级分类，适合学习应用按词书划分

### 5. kajweb/dict

- **项目地址**: https://github.com/kajweb/dict
- **数据格式**: JSON
- **覆盖**: CET4/6、考研、雅思、托福、SAT、GMAT、GRE 等
- **评价**: 部分含例句

---

## 二、同义词词典 / Thesaurus

### 6. Open English WordNet（强烈推荐）

- **项目地址**: https://github.com/globalwordnet/english-wordnet
- **Python 接口**: https://github.com/goodmami/wn （`pip install wn`）
- **数据格式**: LMF(XML) / JSON / RDF / WNDB
- **数据量**: 120,564 synsets，161,705 词，418,168 词义关系
- **例句**: ✅ 每个 synset 含定义和示例句
- **语境区分**: ✅ 通过 synset 区分不同义项
- **许可证**: CC BY 4.0
- **Python 集成**: `pip install wn` 直接使用

```python
import wn
wn.download("oewn:2025")
for ss in wn.synsets("abandon"):
    print(f"释义: {ss.definition()}")
    print(f"同义词: {[w.lemma() for w in ss.words()]}")
    print(f"例句: {ss.examples()}")
```

**评价**: 最适合做同义词辨析的数据源，synset 机制天然支持"同一词在不同语境下的不同含义及其同义词"

### 7. Moby Thesaurus

- **项目地址**: https://github.com/words/moby
- **原始来源**: Project Gutenberg #3202
- **数据格式**: 纯文本 ASCII / JSON
- **数据量**: 30,000+ 根词条，2,500,000+ 同义词关系
- **语境区分**: ❌（同义词按相关性排列但无语境区分）
- **许可证**: Public Domain（公共领域，无任何限制）
- **评价**: 数据量巨大，完全免费，但缺少语境辨析

### 8. zaibacu/thesaurus

- **项目地址**: https://github.com/zaibacu/thesaurus
- **数据格式**: JSONL
- **来源**: 从 WordNet 提取
- **字段**: word、wordnet_id、key（义项区分）、pos、synonyms、description
- **语境区分**: ✅ 通过 key 区分不同含义
- **许可证**: MIT
- **Python 集成**: `pip install thesaurus`
- **评价**: 轻量级方案，带义项区分

### 9. Wordset Dictionary

- **项目地址**: https://github.com/wordset/wordset-dictionary
- **数据格式**: JSON（按首字母分文件）
- **例句**: ✅ 人工审核
- **语境区分**: ✅ 多 meaning
- **许可证**: CC BY-SA 4.0
- **评价**: 数据质量高，例句经过人工修改

### 10. WordNet to JSON

- **项目地址**: https://github.com/fluhus/wordnet-to-json
- **数据格式**: JSON
- **内容**: 完整 WordNet 数据库 JSON 转储
- **许可证**: WordNet License
- **评价**: 适合不想用 `wn` 库时直接加载

---

## 三、GPT 生成的高质量词汇数据

### 11. DictionaryByGPT4（推荐）

- **项目地址**: https://github.com/Ceelog/DictionaryByGPT4
- **数据格式**: JSON / Markdown
- **数据量**: 8,000+ 单词（初中、高中、CET4/6）
- **字段**: 词义、例句、词根词缀、变形、文化背景、记忆技巧、小故事
- **许可证**: MIT
- **评价**: 数据质量非常高，每个单词分析详细。注意可能有 AI 生成错误

---

## 四、MDX 词典解析工具

如需使用现有 MDX 格式词典（牛津、朗文、柯林斯等）：

- **readmdict**: https://github.com/ffreemt/readmdict — `pip install readmdict`
- **mdict-query**: https://github.com/mmjang/mdict-query — 支持 mdx 查词 + 转 SQLite
- **medict**: https://github.com/terasum/medict — 跨平台词典应用

---

## 五、其他相关资源

| 项目 | 地址 | 说明 |
|------|------|------|
| FreeDict | https://freedict.org/ | 140+ 种自由双语词典，GPL |
| engra | https://github.com/bonaysoft/engra | 英语词根词缀数据库 |
| funNLP | https://github.com/fighting41love/funNLP | NLP 资源合集（中文同义词库） |
| near-synonym | https://github.com/yongzhuo/near-synonym | 基于 LLM 的中文近义/反义词 |

---

## 六、本项目采用方案

### 当前选择：基于词书内部的中文含义匹配

**不使用外部词库**，原因：
1. 学生只学了词书里的单词，同义词冲突只发生在已学范围内
2. 词书数据分析显示 42.5% 的单词存在同义冲突，覆盖面足够
3. 外部词库会过度匹配（学生根本不会想到没学过的同义词）

**实现方式**：
- 服务启动时，遍历所有词书提取中文含义关键词
- 建立 `中文含义 → [英文单词集合]` 索引
- 反向建立 `英文单词 → 同义词集合` 映射
- 听写判定时，查同义词集合给出友好提示

### 未来可扩展

如需更精准的同义词辨析（如区分 abandon vs give up 的使用场景），可引入：
1. **Open English WordNet** — 按 synset 区分语境
2. **DictionaryByGPT4** — 补充例句和文化背景
3. **ECDICT** — 扩大基础词库覆盖
